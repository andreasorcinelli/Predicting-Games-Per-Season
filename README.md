## The Question

For our second project at Metis, we were tasked with scraping some information from the web and building linear regression models from which we could learn something about the information that we scraped.

Its July 2018 and the world cup has just wrapped up, and after a tournament filled with upsets and surprises, soccer (or football as I am going to refer to it going forward) is definitely on the forefront of  a lot of peoples' minds. For example, just days after Portugal was eliminated in the knockout round, Cristiano Rinaldo (arguably the world’s most famous football player) announced that he was leaving Real Madrid to go to Juventus. Rinaldo had an amazing season (for example, Real Madrid made history by winning the Champions' league for the third year in a row) and while Rinaldo shows no signs of slowing down, 33 is not young for a football player. Given that Juventus paid 30 million Euro to acquire Rinaldo, they likely want to be able to predict the return on that investment. In other words, they might want to know how much he will play in upcoming seasons. So for Project Luther, I decided to pretend that Massimiliano Allegri, the general manager for Juventus, approached me to see if I could predict how much Rinaldo would play next season. More globally, I thought of this as a challenge to see if I could predict how much football players would play based on their stats from the previous season.

## The Approach

To answer this question I first scraped data from Sports Reference.com using Beautiful Soup and parsed the html that I scraped. Fortunately, all of the data that I was interested in was in one handy table, aptly named “Player Stats". Next, I preprocessed the data by removing null values and empty columns and by creating features for each player for each year that reflected their stats from the previous year (basically by shifting all the data back in time one year and leaving data for the first year the player played blank). In this way, I could use stats from previous years to predict the next year's performance.

Next, I set aside 10 percent of the data as a hold out set. My thinking in doing this was that I would train models on larger proportion of my dataset and then compare the training models to the results from the hold out set, as a true test of the model’s predictability.

Next, I did some exploratory data analyses. I looked at correlations between several potential features and the target, and looked at the distribution of the target. I even played around with a couple  different options for what the target variable would be. In other words, I tried different options for operationalizing "how much a player would play.” Here, I used both overall minutes player each season and games played each season as target variables and while the distribution of overall minutes per season was more symmetrical (and thus less skewed) then the distribution of games per season, I thought that overall minutes per season was not a very intuitive metric. What does it mean to predict that a player will play 2000 minutes in a given season? That’s kinda hard to interpret; it is much easier to understand that a player will play 30 games in a given season. So while the distribution for games per season might not be as suitable for regression as the distribution for minutes per season, I decided to go with games because it made for a more intuitive and explainable target.

## The Results

Next I fit a linear model predicting how many games a player would play based on previous years stats. My approach was to systematically enter  features into a standard ordinary least squares regression one at a time, beginning with the most highly correlated feature and working my way down. I added previous minutes, previous games, previous age, previous fouls, previous assists, previous goals, and previous red cards in that order as those were the most highly correlated features. The inclusion of previous minutes alone resulted in an R^2 of .129. Not very high. By the time I got to previous age, the R^2 was up to .160. Still not great, but we’re doing better. By the time I got to previous red cards, the R^2 was up to .163. Not a tremendous improvement. In the interest of balancing simplicity of the model with predictability, I decided to remove previous fouls, previous assists, previous goals, and previous red cards. They were not adding much predictive power to the model and the additional parameters were making the model more complex. So out they went.

Next I ran the best OLS model (with previous minutes, previous games, and previous age as features) with cross validation on my training dataset and I did diagnostics on the results. So the good news for this model was that the 5 CV values for  R^2 were stable, all ranging right around 0.16, but the bad news was that the residuals did not look great. The model over-predicted for values in the low end of the range and under-predicted for values in the high end of the range. Because the model was clearly missing some signal, I decided to add in some additional features.

So next, I ran a second degree polynomial model with the same features from the linear model with cross validation and repeated regression diagnostics. And this improved the model. Not only did the  R^2 increase to .18 but the residuals were more evenly distributed around mean 0. So progress I thought!

Finally I ran the linear and the polynomial models against the holdout data. In this case, the linear and the polynomial models performed about the same, both returning R^2 values of .12. So it seems the addition of the second degree polynomial terms did not help the model’s predictability as much as I thought.

Because the R^2 for these models is so low, I know that there is a lot of unexplained variance or room for improvement. So as a next steps, I want to add some more data, for example how much money players made in precious seasons, and I also want to more thoroughly check the data for outliers, which I did not do in these iterations of the models.

## The Takeaway

What I learned from these models is that how much a player played last season is a predictor of how much a player will play next season, but there are other important factors that I did not capture in this series of models.  Previous age also matters (the coefficients were all negative, so lower age predicts more playing time) but slightly less then games played in the previous season.

So when I go give my buddy Massimiliano a status report on the project, I will tell him not to worry. Rinaldo played a total 54 games last season so he is likely to play in a lot of games this season, but at the same time, he is getting on in age, so he might want to look into signing some young blood in the near future. But I will tell him to take all of this with a grain of salt; the models did not perform well on either the training or the my holdout data, so clearly I am not capturing some important signal. I will persevere and check back in with Max after another round of scraping and feature engineering. Addio till next time!
